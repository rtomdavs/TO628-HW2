---
title: "Homework 2: Stacked Model"
author: "Tom Davis and Jeremy Zhou"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: spacelab
    highlight: zenburn
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Initial Data Setup

## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

summary(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```


## Getting Train and Test Samples

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 0.5*nrow(tele_norm)) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]

#Creating Full Training and Testing Datasets
tele_test_full <- tele_norm[test_set, ]
tele_train_full <- tele_norm[-test_set, ]

```


# Building Our Models

## Logistic Regression Model Creation
```{r}
LogModel <- lm(yyes ~ ., data = tele_train_full)
```

## Logistic Model Testing
```{r}
library(caret)
LogPred <- predict(LogModel, tele_test_full)
predbin_log <- ifelse(LogPred >= 0.5, 1, 0)
confusionMatrix(as.factor(predbin_log), as.factor(tele_test_full$yyes), positive = "1")

#Kappa for this model = 0.2826
```

## KNN Model Creation
```{r, cache=TRUE}
library(class)

#Output is the prediction for the testing dataset
KNNmodel <- knn(tele_train, tele_test, tele_train_labels, k = 100)
```

## KNN Model Testing
```{r}
confusionMatrix(as.factor(KNNmodel), as.factor(tele_test_labels), positive = "1")

#Kappa for this model = 0.1989
```


## ANN Model Creation
```{r, cache= TRUE}
# install.packages('neuralnet')
library(neuralnet)
model_ann <- neuralnet(yyes ~ ., data = tele_train_full, hidden = 1)
plot(model_ann)
```

## ANN Model Testing
```{r, cache= TRUE}
library (caret)
ann_pred <- predict(model_ann, tele_test_full)
predbin_ann <- ifelse(ann_pred >= 0.5, 1, 0)
confusionMatrix(as.factor(predbin_ann), as.factor(tele_test_full$yyes), positive = "1")

#Kappa for this model = 0.3072
```

## Decision Tree Model Creation
```{r}
library(C50)

teletree <- C5.0(as.factor(yyes) ~., data=tele_train_full)
```

## Decision Tree Model Testing
```{r}
tree_pred <- predict(teletree, tele_test_full)
confusionMatrix(as.factor(tree_pred), as.factor(tele_test_full$yyes), positive = "1")

#Kappa for this model is 0.3623
```


## Random Forest Model Creation
```{r}
library(randomForest)

forestmodel <- randomForest(as.factor(yyes) ~., data = tele_train_full)
```


## Random Forest Model
```{r}
forest_pred <- predict(forestmodel, tele_test_full)

confusionMatrix(as.factor(forest_pred), as.factor(tele_test_full$yyes), positive = "1")

#Kappa for this model is 0.3124
```


# Combining Our Models

## Adding Prediction Columns for Every Model
```{r}
library(dplyr)

telestack <- data.frame(tele_test_full$yyes, LogPred, KNNmodel, ann_pred, tree_pred, forest_pred)

colnames(telestack)[1] = "yyes"
colnames(telestack)[3] = "KNNPred"
colnames(telestack)[4] = "ANNPred"
colnames(telestack)[5] = "TreePred"
colnames(telestack)[6] = "ForestPred"

summary(telestack)
```

## Test and Train for Telestack
```{r}
set.seed(12345)
trainrows <- sample(nrow(telestack), 0.8*nrow(telestack))

tt_train <- telestack[trainrows, ]
tt_test <- telestack[-trainrows, ]
```

## Decision Tree on Telestack
```{r}
tt_tree <- C5.0(as.factor(yyes) ~., data = tt_train)

plot(tt_tree)
```

## Evaluating Decision Tree on Telestack
```{r}
tt_tree_pred <- predict(tt_tree, tt_test)

confusionMatrix(as.factor(tt_tree_pred), as.factor(tt_test$yyes), positive = "1")
```


# Building Our Improved Models

# Adding Cost Matrix to Decision Tree
```{r}
error_cost = matrix(c(0, 1, 6, 0), nrow = 2)
error_cost

errormodel <- C5.0(as.factor(yyes) ~., data = tele_train_full, costs = error_cost)

errorpred <- predict(errormodel, tele_test_full)
confusionMatrix(as.factor(errorpred), as.factor(tele_test_full$yyes), positive = "1")
```

## Logistic Regression Model Creation
```{r}
LogModel2 <- lm(yyes ~ ., data = tele_train_full)
```

## Logistic Model Testing
```{r}
library(caret)
LogPred2 <- predict(LogModel2, tele_test_full)
predbin_log2 <- ifelse(LogPred2 >= 0.2, 1, 0)
confusionMatrix(as.factor(predbin_log2), as.factor(tele_test_full$yyes), positive = "1")

#Kappa for this model = 0.4123
```

## KNN Model Creation
```{r, cache=TRUE}
library(class)

#Output is the prediction for the testing dataset
KNNmodel2 <- knn(tele_train, tele_test, tele_train_labels, k = 50)
```

## KNN Model Testing
```{r}
confusionMatrix(as.factor(KNNmodel2), as.factor(tele_test_labels), positive = "1")

#Kappa for this model = 0.1989
```


## ANN Model Creation
```{r, cache= TRUE}
# install.packages('neuralnet')
library(neuralnet)
model_ann2 <- neuralnet(yyes ~ ., data = tele_train_full, hidden = 1)
plot(model_ann2)
```

## ANN Model Testing
```{r, cache= TRUE}
library (caret)
ann_pred2 <- predict(model_ann2, tele_test_full)
predbin_ann2 <- ifelse(ann_pred2 >= 0.2, 1, 0)
confusionMatrix(as.factor(predbin_ann2), as.factor(tele_test_full$yyes), positive = "1")

#Kappa for this model = 0.3072
```


## Random Forest Model Creation
```{r}
library(randomForest)

forestmodel2 <- randomForest(as.factor(yyes) ~., data = tele_train_full, costs = error_cost)
```


## Random Forest Model
```{r}
forest_pred2 <- predict(forestmodel2, tele_test_full)

confusionMatrix(as.factor(forest_pred2), as.factor(tele_test_full$yyes), positive = "1")

#Kappa for this model is 0.3124
```
